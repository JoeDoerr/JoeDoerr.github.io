<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <link rel="stylesheet" href="styles.css">
    <title>Image and Text Example</title>
</head>
<body>

<p>
  <strong>Joe Hermann Doerr</strong>
</p>
<img src="image.PNG" alt="My Image">
<p>
  <strong>Rutgers University NB,
  </strong>
  <a target="_blank" href="mailto:joehdoerr@gmail.com">
    <span style="color:rgb(17, 85, 204);">
      <strong>joehdoerr@gmail.com</strong>
    </span>
  </a>
  <strong>,
  </strong>
  <a target="_blank" href="mailto:jhd79@rutgers.edu">
    <span style="color:rgb(17, 85, 204);">
      <strong>jhd79@rutgers.edu</strong>
    </span>
  </a>
</p>
<p>
  <strong>
    <em>Reinforcement Learning, Robotics, Deep learning</em>
  </strong>
</p>
<p>
  <strong>Links:</strong>
</p>
<p>Google scholar:
  <a target="_blank" href="https://scholar.google.com/citations?user=1OeZRecAAAAJ&amp;hl=en&amp;oi=ao">
    <span style="color:rgb(17, 85, 204);">https://scholar.google.com/citations?user=1OeZRecAAAAJ&amp;hl=en&amp;oi=ao</span>
  </a>
</p>
<p>First publication:<strong></strong>
  <a target="_blank" href="https://opg.optica.org/abstract.cfm?uri=DH-2022-M6A.2">
    <span style="color:rgb(17, 85, 204);">https://opg.optica.org/abstract.cfm?uri=DH-2022-M6A.2</span>
  </a>
</p>
<p>Longer version of publication:
  <a target="_blank" href="https://arxiv.org/abs/2304.06042">
    <span style="color:rgb(17, 85, 204);">https://arxiv.org/abs/2304.06042</span>
  </a>
</p>
<p>Generalization Partial Review:
  <a target="_blank" href="https://joedoerr.bitbucket.io/">
    <span style="color:rgb(17, 85, 204);">https://joedoerr.bitbucket.io/</span>
  </a>
</p>
<p>Personal Projects:
  <a target="_blank" href="https://bitbucket.org/JoeDoerr/researchdl/src/master/">
    <span style="color:rgb(17, 85, 204);">https://bitbucket.org/JoeDoerr/researchdl/src/master/</span>
  </a>
</p>
<p>SAC/DDPG implementation:
  <a target="_blank" href="https://bitbucket.org/JoeDoerr/soft-actor-critic-modifiable/src/main">
    <span style="color:rgb(17, 85, 204);">https://bitbucket.org/JoeDoerr/soft-actor-critic-modifiable/src/main</span>
  </a>
</p>
<p>
  <strong>Interests:</strong>
</p>
<p>I am interested in creating intelligent robots that can perform well in real world scenarios. To this end, my focus is on improving locomotion, navigation, and manipulation capabilities for intelligent robots within environments characterized by stochasticity, noise, and high complexity. RL is especially captivating due to not only the potential it has to autonomously find solutions in these environments, but the controllability over the solutions. I am specifically interested in the manipulation of RL design to find behaviors that are robust to observational noise or environmental stochasticity.</p>
<p>Additionally, I am interested in exploring the synergy between DL and RL, particularly in terms of generalization across varying task attributes, cardinally different tasks, and simulation to real life. Moreover, I am interested in targeted information capture within DL models both facilitated by RL and to facilitate RL. In the interplay between RL and robotic manipulation and locomotion, I am interested in finding solutions that not only use RL, but also properly leverage classical robotic control methods.</p>
<p>
  <strong>Work Experience:</strong>
</p>
<p>
  <strong>Rutgers University, PRACSYS, Robotics Lab</strong>
  <strong></strong>&nbsp; &nbsp;
</p>
<p>October 2023 - Present (~2 months)</p>
<p>Research Assistant</p>
<p>In person I attend weekly discussions about project updates and future directions with professors. I also attend weekly meetings where PhD students present papers of interest and hold a discussion.</p>
<p>
  <span style="text-decoration:underline;">Supervisor:</span>
</p>
<p>Prof. Kostas Bekris</p>
<p>
  <span style="text-decoration:underline;">Notable work:</span>
</p>
<p>I am currently working with a PhD student on low tolerance peg insertion.</p>
<p>Created reinforcement learning (RL) task environments in IsaacGym for low tolerance peg insertion.</p>
<p>Assisted in developing methods for improving robustness of peg insertion policy to observation noise.</p>
<p>
  <strong>University of Central Florida, CREOL, Optical Imaging System Lab</strong>
</p>
<p>June 2021 - Jan 2023 (~19 months)</p>
<p>Research Intern and Consultant</p>
<p>I worked as a remote research consultant for 15 hours a week during the semester and 40 hours a week during the summer. I went to work in person in Florida as a research intern during my second summer working there.&nbsp;</p>
<p>
  <span style="text-decoration:underline;">Supervisors:</span>
</p>
<p>Prof. Shuo (Sean) Pang, Prof. Guifang Li, Dr. Zheyuan Zhu</p>
<p>
  <span style="text-decoration:underline;">Publication date and title:</span>
</p>
<p>Shorter version: Multiplane light conversion design with physical neural network, 8/1/2022</p>
<p>Longer version: A physical neural network training approach toward multi-plane light conversion design (process of resubmission currently), 4/6/2023</p>
<p>
  <span style="text-decoration:underline;">Notable work done:</span>
</p>
<ul>
  <li>Developed a Tensorflow compilation process for the deployment of neural networks and scientific computing applications on an optical computation device simulated on FPGA. This is an important contribution as it bridges the gap between high level deep learning programming and optical computation.</li>
  <li>Presented an in-person demonstration of the Tensorflow compilation using the simulated optical device to a program manager sponsoring the optical computing project.</li>
  <li>Programmed FPGA-based optical computation emulator in Vitis embedded C to test our software while the optical computation chip was in development.</li>
  <li>Wrote an ethernet library in C then wrapped in Python for communication with FPGA.</li>
  <li>Coded multi-plane light conversion simulation in Tensorflow with parallel GPU computation and SLURM job scheduling to perform extensive hyperparameter scans autonomously and efficiently.</li>
</ul>
<p>
  <strong>Specific methodology interests:</strong>
</p>
<p>
  <em>In approximate order of familiarity/interest</em>
</p>
<ul>
  <li>Understanding how underlying systems can develop to create a generalizable system</li>
  <ul>
    <li>Through understanding hierarchical patterns and ChatGPT limitations and capabilities.</li>
    <li>Exploration of how syntax can be trained separately from topic content and how topic information can be formalized for novel situation use.&nbsp;</li>
  </ul>
  <li>TD3,SAC,PPO</li>
  <li>Hierarchical RL</li>
  <li>Offline RL</li>
  <li>Transformers</li>
  <li>Convolutional Networks</li>
  <li>Ignoring irrelevant information: Contrastive RL, Bisimulation metrics</li>
  <li>Multi-task RL</li>
  <li>Unsupervised skill discovery</li>
  <li>Adversarial RL</li>
</ul>
<p>
  <strong>Specific problem interests:</strong>
</p>
<p>
  <em>I have yet to develop a comprehensive understanding of the paradigm of the field for any of these subjects. They are interests I have been exploring from reading a few papers.</em>
</p>
<ul>
  <li>Peg insertion</li>
  <li>Quadruped robust locomotion</li>
  <li>Quadruped jumping motions</li>
  <li>Prehensile manipulation</li>
  <li>Tensegrity robotics</li>
  <li>Realistic motion development for pet robotics</li>
  <li>Path planning in stochastic environments</li>
  <li>SLAM for self driving cars</li>
</ul>

</body>
</html>
